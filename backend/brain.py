# backend/brain.py
import os
import chromadb
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader
import ollama
from PIL import Image

# Setup
db_client = chromadb.PersistentClient(path="./cortex_memory")
collection = db_client.get_or_create_collection(name="my_documents")
embed_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ (Magic Trick!) ---
def translate_query(thai_query):
    """‡πÅ‡∏õ‡∏•‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ó‡∏¢ -> ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô"""
    # ‡∏ñ‡πâ‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏°‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•
    if all(ord(c) < 128 for c in thai_query.replace(" ", "")):
        return thai_query
        
    try:
        res = ollama.chat(model='mistral', messages=[{
            'role': 'user',
            'content': f"Translate this Thai text to English keywords for a search engine. Output ONLY the English translation. Text: '{thai_query}'"
        }])
        english_query = res['message']['content'].strip()
        print(f"üáπüá≠ Query: {thai_query} -> üá¨üáß Translated: {english_query}")
        return english_query
    except:
        return thai_query

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
def analyze_image(image_path):
    print(f"   üëÅÔ∏è Looking at: {os.path.basename(image_path)}")
    try:
        res = ollama.chat(
            model='llava', 
            messages=[{
                'role': 'user',
                'content': 'Describe this image in detail. Focus on text, numbers, QR codes, and the type of document (e.g., slip, receipt, screen, interface).',
                'images': [image_path]
            }]
        )
        return res['message']['content']
    except Exception as e:
        print(f"      ‚ùå Image Error: {e}")
        return ""

def read_file_content(file_path):
    ext = file_path.split('.')[-1].lower()
    content = ""
    try:
        if ext == 'pdf':
            reader = PdfReader(file_path)
            for page in reader.pages:
                text = page.extract_text()
                if text: content += text + "\n"
        elif ext in ['txt', 'md', 'csv', 'json']:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        elif ext in ['jpg', 'jpeg', 'png']:
            content = analyze_image(file_path)
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    return content

def ingest_folder(folder_path):
    count = 0
    print(f"üìÇ Scanning: {folder_path}")
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(('.txt', '.md', '.pdf', '.jpg', '.jpeg', '.png')):
                full_path = os.path.join(root, file)
                existing = collection.get(ids=[full_path])
                if existing['ids']: continue # Skip existing

                text = read_file_content(full_path)
                if not text.strip(): continue

                embedding = embed_model.encode(text).tolist()
                collection.add(
                    documents=[text],
                    metadatas=[{"source": full_path, "filename": file}],
                    ids=[full_path],
                    embeddings=[embedding]
                )
                count += 1
                print(f"   ‚úÖ Memorized: {file}")
    return {"status": "success", "files_processed": count}

# --- ‡πÅ‡∏Å‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (Search) ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ---
def search_documents(query_text, n_results=5):
    english_query = translate_query(query_text)
    query_vec = embed_model.encode(english_query).tolist()
    results = collection.query(query_embeddings=[query_vec], n_results=n_results)
    
    formatted_results = []
    if results['documents']:
        for i in range(len(results['documents'][0])):
            distance = results['distances'][0][i]
            
            # --- ‡∏™‡∏π‡∏ï‡∏£‡πÇ‡∏Å‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏¢ (Calibration) ---
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏π‡∏ï‡∏£‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏à‡∏∏‡∏Å‡∏ó‡∏µ‡πà 99%)
            # ‡∏™‡∏°‡∏°‡∏ï‡∏¥ distance ‡∏≠‡∏¢‡∏π‡πà‡∏ä‡πà‡∏ß‡∏á 10-40
            # Distance 10 -> 1 / 1.1 = 0.90 (90%)
            # Distance 30 -> 1 / 1.3 = 0.76 (76%)
            final_score = 1 / (1 + (distance / 100))
            
            formatted_results.append({
                "content": results['documents'][0][i],
                "source": results['metadatas'][0][i]['filename'],
                "path": results['metadatas'][0][i]['source'],
                "score": final_score 
            })
            
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢
    formatted_results.sort(key=lambda x: x['score'], reverse=True)
    return formatted_results

# --- ‡πÅ‡∏Å‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (Prompt Engineering) ---
def generate_answer(query, context_results):
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô 50% (0.5) ‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI ‡∏≠‡πà‡∏≤‡∏ô
    high_quality_context = [item for item in context_results if item['score'] > 0.5]
    
    if not high_quality_context and context_results:
        high_quality_context = [context_results[0]]
    
    context_text = ""
    for item in high_quality_context:
        context_text += f"[Source: {item['source']}] Content: {item['content']}\n\n"
    
    prompt = f"""
    Context:
    {context_text}
    
    User Query: "{query}"
    
    Task: Answer the query based ONLY on the provided Context.
    1. Answer in Thai language ONLY. (‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
    2. Keep the answer concise and to the point.
    3. If the context has an image description matching the query, confirm it.
    4. Do not mention "Based on the context" (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."), just answer directly.
    """

    try:
        response = ollama.chat(model='mistral', messages=[
            {'role': 'user', 'content': prompt},
        ])
        return response['message']['content']
    except Exception as e:
        return f"AI Error: {str(e)}"